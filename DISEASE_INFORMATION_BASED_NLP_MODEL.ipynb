{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Desktop/NLP_MODEL_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing important libraries related to NLP.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the text file containing medical question and answer pairs in order to train the model.\n",
    "\n",
    "df = pd.read_csv('Question_Answer.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52138e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original df length: ',len(df))\n",
    "df.dropna(subset=['question'], inplace=True)\n",
    "df.dropna(subset=['answer'], inplace=True)\n",
    "df.dropna(subset=['focus_area'], inplace=True)\n",
    "df.dropna(subset=['source'])\n",
    "df = df[~df.question.str.contains('#')] # remove badly formatted questions\n",
    "df = df[~df.answer.isin(['no','yes','Yes','No','No,','Yes,','No.','Yes.','yes.','no.'])] # remove yes/no questions\n",
    "print('new df length: ',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55483708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates( subset='question' )\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['focus_area'] + ' ' + df['question']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0081308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df[['question', 'answer']]\n",
    "df01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f407d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( type( tuple( df['question'] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32721f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    pos_tags = pos_tag(words)\n",
    "    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n",
    "    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n",
    "    \n",
    "    lemmas = []\n",
    "    for w in non_punctuation:\n",
    "        if w[1].startswith('J'):\n",
    "            pos = wordnet.ADJ\n",
    "        elif w[1].startswith('V'):\n",
    "            pos = wordnet.VERB\n",
    "        elif w[1].startswith('N'):\n",
    "            pos = wordnet.NOUN\n",
    "        elif w[1].startswith('R'):\n",
    "            pos = wordnet.ADV\n",
    "        else:\n",
    "            pos = wordnet.NOUN\n",
    "        \n",
    "        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n",
    "        \n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "#tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tuple(df01['question']))\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question):\n",
    "    \n",
    "    query_vect = tfidf_vectorizer.transform([question])\n",
    "    similarity = cosine_similarity(query_vect, tfidf_matrix)\n",
    "    similarity_max = np.argmax(similarity)\n",
    "    \n",
    "    print('> Answer:\\n- {}'.format(df01.iloc[similarity_max]['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4867905",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_user = input('Type your question here: ')\n",
    "question_answer(question_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
